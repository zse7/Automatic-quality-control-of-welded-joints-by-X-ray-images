import os
import shutil
import pandas as pd
import random
from collections import defaultdict

def move_orphan_images(dataset_path, orphans_dir='notebooks/orphans'):
    """
    –ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–µ–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö .txt —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫—É orphans
    """
    print("=== –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –º–µ—Ç–æ–∫ ===")
    
    os.makedirs(orphans_dir, exist_ok=True)
    
    splits = ['train', 'val', 'test']
    moved_count = 0
    
    for split in splits:
        images_path = os.path.join(dataset_path, split, 'images')
        labels_path = os.path.join(dataset_path, split, 'labels')
        
        if not os.path.exists(images_path):
            continue
            
        for image_file in os.listdir(images_path):
            if image_file.endswith(('.jpg', '.jpeg', '.png')):
                base_name = os.path.splitext(image_file)[0]
                label_file = base_name + '.txt'
                label_path = os.path.join(labels_path, label_file)
                
                # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ .txt —Ñ–∞–π–ª–∞
                if not os.path.exists(label_path):
                    src_image_path = os.path.join(images_path, image_file)
                    dst_image_path = os.path.join(orphans_dir, image_file)
                    
                    shutil.move(src_image_path, dst_image_path)
                    moved_count += 1
                    print(f"–ü–µ—Ä–µ–º–µ—â–µ–Ω–æ: {image_file}")
    
    print(f"–í—Å–µ–≥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –º–µ—Ç–æ–∫: {moved_count}")
    return moved_count

def move_orphan_labels(dataset_path, orphans_dir='notebooks/orphans'):
    """
    –ü–µ—Ä–µ–º–µ—â–∞–µ—Ç .txt —Ñ–∞–π–ª—ã –±–µ–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫—É orphans
    """
    print("\n=== –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ orphan .txt —Ñ–∞–π–ª–æ–≤ ===")
    
    os.makedirs(orphans_dir, exist_ok=True)
    
    splits = ['train', 'val', 'test']
    moved_count = 0
    
    for split in splits:
        images_path = os.path.join(dataset_path, split, 'images')
        labels_path = os.path.join(dataset_path, split, 'labels')
        
        if not os.path.exists(labels_path):
            continue
            
        for label_file in os.listdir(labels_path):
            if label_file.endswith('.txt'):
                base_name = os.path.splitext(label_file)[0]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                image_found = False
                for ext in ['.jpg', '.jpeg', '.png']:
                    image_path = os.path.join(images_path, base_name + ext)
                    if os.path.exists(image_path):
                        image_found = True
                        break
                
                # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                if not image_found:
                    src_label_path = os.path.join(labels_path, label_file)
                    dst_label_path = os.path.join(orphans_dir, label_file)
                    
                    shutil.move(src_label_path, dst_label_path)
                    moved_count += 1
                    print(f"–ü–µ—Ä–µ–º–µ—â–µ–Ω–æ: {label_file}")
    
    print(f"–í—Å–µ–≥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ orphan .txt —Ñ–∞–π–ª–æ–≤: {moved_count}")
    return moved_count


def remap_labels_polygons(source_dataset_path, target_dataset_path, class_mapping=None):
    """
    –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –ø–µ—Ä–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏
    class_mapping: —Å–ª–æ–≤–∞—Ä—å {—Å—Ç–∞—Ä—ã–π_–∫–ª–∞—Å—Å: –Ω–æ–≤—ã–π_–∫–ª–∞—Å—Å}
    """
    print("\n=== –ü–µ—Ä–µ—Ä–∞–∑–º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–æ–≤ ===")
    
    if class_mapping is None:
        # –ü—Ä–∏–º–µ—Ä –º–∞–ø–ø–∏–Ω–≥–∞ –∫–ª–∞—Å—Å–æ–≤ - –Ω–∞—Å—Ç—Ä–æ–π –ø–æ–¥ —Å–≤–æ–∏ –Ω—É–∂–¥—ã
        class_mapping = {
            '0': '0',  # —Å—Ç–∞—Ä—ã–π –∫–ª–∞—Å—Å 0 -> –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å 0
            '1': '1',  # —Å—Ç–∞—Ä—ã–π –∫–ª–∞—Å—Å 1 -> –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å 1
            '2': '1',  # —Å—Ç–∞—Ä—ã–π –∫–ª–∞—Å—Å 2 -> –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å 1 (–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤)
            '3': '2',  # —Å—Ç–∞—Ä—ã–π –∫–ª–∞—Å—Å 3 -> –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å 2
        }
    
    splits = ['train', 'val', 'test']
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ü–µ–ª–µ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    for split in splits:
        os.makedirs(os.path.join(target_dataset_path, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(target_dataset_path, split, 'labels'), exist_ok=True)
    
    total_remapped = 0
    
    for split in splits:
        source_images_path = os.path.join(source_dataset_path, split, 'images')
        source_labels_path = os.path.join(source_dataset_path, split, 'labels')
        target_images_path = os.path.join(target_dataset_path, split, 'images')
        target_labels_path = os.path.join(target_dataset_path, split, 'labels')
        
        if not os.path.exists(source_images_path):
            continue
        
        # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for image_file in os.listdir(source_images_path):
            if image_file.endswith(('.jpg', '.jpeg', '.png')):
                src_image_path = os.path.join(source_images_path, image_file)
                dst_image_path = os.path.join(target_images_path, image_file)
                shutil.copy2(src_image_path, dst_image_path)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ –∫–æ–ø–∏—Ä—É–µ–º labels —Å –ø–µ—Ä–µ—Ä–∞–∑–º–µ—Ç–∫–æ–π
        for label_file in os.listdir(source_labels_path):
            if label_file.endswith('.txt'):
                src_label_path = os.path.join(source_labels_path, label_file)
                dst_label_path = os.path.join(target_labels_path, label_file)
                
                with open(src_label_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                new_lines = []
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    
                    parts = line.split()
                    if len(parts) >= 5:  # YOLO —Ñ–æ—Ä–º–∞—Ç: class x_center y_center width height
                        old_class = parts[0]
                        new_class = class_mapping.get(old_class, old_class)  # –ø—Ä–∏–º–µ–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥
                        
                        if new_class != old_class:
                            total_remapped += 1
                        
                        new_line = f"{new_class} " + " ".join(parts[1:]) + "\n"
                        new_lines.append(new_line)
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–µ—Ä–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                with open(dst_label_path, 'w', encoding='utf-8') as f:
                    f.writelines(new_lines)
    
    print(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {target_dataset_path}")
    print(f"–í—Å–µ–≥–æ –ø–µ—Ä–µ—Ä–∞–∑–º–µ—á–µ–Ω–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π: {total_remapped}")
    print(f"–ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤: {class_mapping}")
    
    return total_remapped

# ==================== –°–ö–†–ò–ü–¢ 4: –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ ====================

def create_stratified_split(dataset_path, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):
    """
    –°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test
    """
    print("\n=== –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ ===")
    
    random.seed(random_state)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
    total_ratio = train_ratio + val_ratio + test_ratio
    if abs(total_ratio - 1.0) > 0.01:
        raise ValueError(f"–°—É–º–º–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–π –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 1.0, –ø–æ–ª—É—á–µ–Ω–æ {total_ratio}")
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ä–∞–±–æ—Ç—ã
    temp_dir = os.path.join(dataset_path, 'temp_reorganization')
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–ø–∫–µ
    splits = ['train', 'val', 'test']
    for split in splits:
        os.makedirs(os.path.join(temp_dir, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(temp_dir, split, 'labels'), exist_ok=True)
    
    # –°–æ–±–∏—Ä–∞–µ–º –í–°–ï —Ñ–∞–π–ª—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø–∞–ø–æ–∫ –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫
    all_files = []
    source_folders = ['train', 'val']
    
    for folder in source_folders:
        images_path = os.path.join(dataset_path, folder, 'images')
        labels_path = os.path.join(dataset_path, folder, 'labels')
        
        if not os.path.exists(images_path):
            continue
            
        for file in os.listdir(images_path):
            if file.endswith(('.jpg', '.jpeg', '.png')):
                base_name = os.path.splitext(file)[0]
                label_file = base_name + '.txt'
                label_path = os.path.join(labels_path, label_file)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                if os.path.exists(label_path):
                    if os.path.getsize(label_path) == 0:
                        category = 'empty'
                    else:
                        category = 'with_annotations'
                else:
                    category = 'no_file'
                
                all_files.append({
                    'source_folder': folder,
                    'base_name': base_name,
                    'image_name': file,
                    'category': category,
                    'image_path': os.path.join(images_path, file),
                    'label_path': label_path if os.path.exists(label_path) else None
                })
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    files_by_category = defaultdict(list)
    for file_info in all_files:
        files_by_category[file_info['category']].append(file_info)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    total_files = len(all_files)
    print("–ò—Å—Ö–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    for category, files in files_by_category.items():
        percentage = (len(files) / total_files) * 100
        print(f"  {category}: {len(files)} —Ñ–∞–π–ª–æ–≤ ({percentage:.1f}%)")
    
    # –°–¢–†–ê–¢–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–û–ï –†–ê–ó–î–ï–õ–ï–ù–ò–ï
    train_files = []
    val_files = []
    test_files = []
    
    for category, category_files in files_by_category.items():
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        random.shuffle(category_files)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–ª–∏—Ç–∞
        n_total = len(category_files)
        n_train = int(n_total * train_ratio)
        n_val = int(n_total * val_ratio)
        n_test = n_total - n_train - n_val  # –û—Å—Ç–∞–≤—à–∏–µ—Å—è —Ñ–∞–π–ª—ã –∏–¥—É—Ç –≤ test
        
        # –†–∞–∑–¥–µ–ª—è–µ–º —Ñ–∞–π–ª—ã
        train_files.extend(category_files[:n_train])
        val_files.extend(category_files[n_train:n_train + n_val])
        test_files.extend(category_files[n_train + n_val:])
        
        print(f"\n–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}':")
        print(f"  Train: {n_train} —Ñ–∞–π–ª–æ–≤ ({n_train/n_total*100:.1f}%)")
        print(f"  Val: {n_val} —Ñ–∞–π–ª–æ–≤ ({n_val/n_total*100:.1f}%)") 
        print(f"  Test: {n_test} —Ñ–∞–π–ª–æ–≤ ({n_test/n_total*100:.1f}%)")
    
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –≤–æ –í–†–ï–ú–ï–ù–ù–´–ï –ø–∞–ø–∫–∏
    def copy_files(files_list, target_split):
        for file_info in files_list:
            # –ü—É—Ç–∏ –∫ –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–∞–º
            src_image_path = file_info['image_path']
            src_label_path = file_info['label_path']
            
            # –ü—É—Ç–∏ –∫ —Ü–µ–ª–µ–≤—ã–º —Ñ–∞–π–ª–∞–º –≤–æ –í–†–ï–ú–ï–ù–ù–û–ô –ø–∞–ø–∫–µ
            dst_image_path = os.path.join(temp_dir, target_split, 'images', file_info['image_name'])
            dst_label_path = os.path.join(temp_dir, target_split, 'labels', file_info['base_name'] + '.txt')
            
            # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            shutil.copy2(src_image_path, dst_image_path)
            
            # –ö–æ–ø–∏—Ä—É–µ–º txt —Ñ–∞–π–ª –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if src_label_path and os.path.exists(src_label_path):
                shutil.copy2(src_label_path, dst_label_path)
    
    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –≤–æ –í–†–ï–ú–ï–ù–ù–´–ï –ø–∞–ø–∫–∏
    print("\n–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
    copy_files(train_files, 'train')
    copy_files(val_files, 'val') 
    copy_files(test_files, 'test')
    
    # –£–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏ –∏ –∑–∞–º–µ–Ω—è–µ–º –∏—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏
    print("–ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏...")
    for split in splits:
        original_split_path = os.path.join(dataset_path, split)
        temp_split_path = os.path.join(temp_dir, split)
        
        # –£–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if os.path.exists(original_split_path):
            shutil.rmtree(original_split_path)
        
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –Ω–∞ –º–µ—Å—Ç–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π
        shutil.move(temp_split_path, original_split_path)
    
    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    shutil.rmtree(temp_dir)
    
    return {
        'train': train_files,
        'val': val_files, 
        'test': test_files
    }

# ==================== –°–ö–†–ò–ü–¢ 5: –†–∞—Å—á–µ—Ç —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ ====================

def calculate_final_stratification(dataset_path):
    """
    –†–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
    """
    splits = ['train', 'val', 'test']
    results = {}
    
    for split in splits:
        images_path = os.path.join(dataset_path, split, 'images')
        labels_path = os.path.join(dataset_path, split, 'labels')
        
        if not os.path.exists(images_path):
            continue
            
        categories = defaultdict(int)
        total_files = 0
        
        for image_file in os.listdir(images_path):
            if image_file.endswith(('.jpg', '.jpeg', '.png')):
                base_name = os.path.splitext(image_file)[0]
                label_path = os.path.join(labels_path, base_name + '.txt')
                
                if os.path.exists(label_path):
                    if os.path.getsize(label_path) == 0:
                        category = 'empty'
                    else:
                        category = 'with_annotations'
                else:
                    category = 'no_file'
                
                categories[category] += 1
                total_files += 1
        
        results[split] = {
            'total': total_files,
            'categories': dict(categories),
            'percentages': {k: (v/total_files)*100 for k, v in categories.items()}
        }
    
    return results

# ==================== –°–ö–†–ò–ü–¢ 6: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ CSV ====================

def dataset_to_csv(dataset_path, output_csv='dataset_stratified.csv'):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç –≤ CSV
    """
    print("\n=== –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ CSV ===")
    
    data = []
    
    splits = ['train', 'val', 'test']
    
    for split in splits:
        images_path = os.path.join(dataset_path, split, 'images')
        labels_path = os.path.join(dataset_path, split, 'labels')
        
        if not os.path.exists(images_path):
            continue
            
        for image_file in os.listdir(images_path):
            if image_file.endswith(('.jpg', '.jpeg', '.png')):
                base_name = os.path.splitext(image_file)[0]
                image_path = os.path.join(images_path, image_file)
                label_path = os.path.join(labels_path, base_name + '.txt')
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
                label_status = "no_file"
                annotations = ""
                file_size = 0
                
                if os.path.exists(label_path):
                    file_size = os.path.getsize(label_path)
                    if file_size == 0:
                        label_status = "empty"
                    else:
                        label_status = "has_annotations"
                        with open(label_path, 'r', encoding='utf-8') as f:
                            annotations = f.read().strip()
                
                data.append({
                    'split': split,
                    'image_path': image_path,
                    'label_path': label_path,
                    'label_status': label_status,
                    'file_size_bytes': file_size,
                    'annotations': annotations,
                    'filename': base_name,
                    'has_annotations': label_status == "has_annotations",
                    'has_empty_txt': label_status == "empty",
                    'no_txt_file': label_status == "no_file"
                })
    
    # –°–æ–∑–¥–∞–µ–º DataFrame –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    df = pd.DataFrame(data)
    df.to_csv(output_csv, index=False, encoding='utf-8')
    
    print(f"–î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_csv}")
    print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
    
    return df

# ==================== –û–°–ù–û–í–ù–û–ô –ë–õ–û–ö –ò–°–ü–û–õ–ù–ï–ù–ò–Ø ====================

if __name__ == "__main__":
    dataset_path = "data/data"
    
    print("üöÄ –ó–ê–ü–£–°–ö –í–°–ï–• –°–ö–†–ò–ü–¢–û–í –ü–†–ï–ü–†–û–¶–ï–°–°–ò–ù–ì–ê –î–ê–ù–ù–´–•\n")
    
    # 1. –û—á–∏—Å—Ç–∫–∞ –æ—Ç orphan —Ñ–∞–π–ª–æ–≤
    print("1. –û—á–∏—Å—Ç–∫–∞ –æ—Ç orphan —Ñ–∞–π–ª–æ–≤...")
    move_orphan_images(dataset_path)
    move_orphan_labels(dataset_path)
    
    # 2. –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    print("\n2. –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ...")
    splits = create_stratified_split(
        dataset_path, 
        train_ratio=0.7, 
        val_ratio=0.15, 
        test_ratio=0.15
    )
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    print("\n3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
    stratification = calculate_final_stratification(dataset_path)
    
    for split, stats in stratification.items():
        print(f"\n{split.upper()}: {stats['total']} —Ñ–∞–π–ª–æ–≤")
        for category, count in stats['categories'].items():
            percentage = stats['percentages'][category]
            print(f"  {category}: {count} —Ñ–∞–π–ª–æ–≤ ({percentage:.1f}%)")
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ CSV
    print("\n4. –°–æ–∑–¥–∞–Ω–∏–µ CSV —Ñ–∞–π–ª–∞...")
    df = dataset_to_csv(dataset_path, "dataset_stratified.csv")
    
    # 5. –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø–µ—Ä–µ—Ä–∞–∑–º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    # print("\n5. –ü–µ—Ä–µ—Ä–∞–∑–º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–æ–≤...")
    remap_labels_polygons(
        source_dataset_path=dataset_path,
        target_dataset_path="data/dataset_2_remap",
        class_mapping={'0': '0', '1': '1', '2': '1', '3': '2'}  # –Ω–∞—Å—Ç—Ä–æ–π –ø–æ–¥ —Å–≤–æ–∏ –∫–ª–∞—Å—Å—ã
    )
    
    print("\n‚úÖ –í–°–ï –°–ö–†–ò–ü–¢–´ –í–´–ü–û–õ–ù–ï–ù–´ –£–°–ü–ï–®–ù–û!")
    print(f"   Train: {len(splits['train'])} —Ñ–∞–π–ª–æ–≤ (70%)")
    print(f"   Val: {len(splits['val'])} —Ñ–∞–π–ª–æ–≤ (15%)")
    print(f"   Test: {len(splits['test'])} —Ñ–∞–π–ª–æ–≤ (15%)")