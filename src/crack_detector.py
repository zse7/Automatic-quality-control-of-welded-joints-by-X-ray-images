import os
import cv2
from pathlib import Path
import json
import random

def create_crack_annotations_for_train_val_test():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –¥–ª—è —Ç—Ä–µ—â–∏–Ω —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ train/val/test"""
    
    # –ü—É—Ç–∏ –∫ –ø–∞–ø–∫–∞–º —Å —Ç—Ä–µ—â–∏–Ω–∞–º–∏ (–≤–∫–ª—é—á–∞—è —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É)
    crack_folders = {
        "train": ["data//data//training//–î–µ—Ñ–µ–∫—Ç 3"],
        "test": ["data//data//testing//–î–µ—Ñ–µ–∫—Ç 3"],
        "val": ["data//data//validation//–î–µ—Ñ–µ–∫—Ç 3"]
    }
    
    # –í—ã—Ö–æ–¥–Ω—ã–µ –ø–∞–ø–∫–∏ –¥–ª—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    output_dirs = {
        "train": Path("data//dataset_2_split//train//labels"),
        "test": Path("data//dataset_2_split//test//labels"),
        "val": Path("data//dataset_2_split//val//labels")
    }
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    for dir_path in output_dirs.values():
        dir_path.mkdir(parents=True, exist_ok=True)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = {"train": 0, "val": 0, "test": 0}
    
    for split_type, folders in crack_folders.items():
        print(f"\nüéØ –û–ë–†–ê–ë–û–¢–ö–ê {split_type.upper()} –î–ê–ù–ù–´–•:")
        
        for crack_folder in folders:
            crack_path = Path(crack_folder)
            
            if not crack_path.exists():
                print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {crack_path}")
                continue
                
            print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏: {crack_path}")
            
            # –ò—â–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ
            image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
            image_files = []
            
            for ext in image_extensions:
                image_files.extend(crack_path.glob(ext))
                image_files.extend(crack_path.glob(ext.upper()))
            
            print(f"   –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}")
            
            for image_path in image_files:
                # –°–æ–∑–¥–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
                annotation_content = create_full_image_annotation(image_path)
                
                # –ò–º—è —Ñ–∞–π–ª–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                annotation_filename = image_path.stem + '.txt'
                annotation_path = output_dirs[split_type] / annotation_filename
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
                with open(annotation_path, 'w', encoding='utf-8') as f:
                    f.write(annotation_content)
                
                stats[split_type] += 1
                print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è: {annotation_filename} -> {split_type}")
    
    # –û—Ç—á–µ—Ç
    print(f"\nüéâ –í–´–ü–û–õ–ù–ï–ù–û!")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   Train: {stats['train']} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
    print(f"   Val: {stats['val']} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
    print(f"   Test: {stats['test']} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
    
    print(f"üíæ –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
    print(f"   Train: {output_dirs['train']}")
    print(f"   Val: {output_dirs['val']}")
    print(f"   Test: {output_dirs['test']}")

def create_crack_annotations_with_split():
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test"""
    
    # –í—Å–µ –ø–∞–ø–∫–∏ —Å —Ç—Ä–µ—â–∏–Ω–∞–º–∏
    all_crack_folders = [
        "data//training//–î–µ—Ñ–µ–∫—Ç 3",
        "data//testing//–î–µ—Ñ–µ–∫—Ç 3", 
        "data//validation//–î–µ—Ñ–µ–∫—Ç 3"
    ]
    
    # –í—ã—Ö–æ–¥–Ω—ã–µ –ø–∞–ø–∫–∏
    train_labels_dir = Path("data//dataset_2_split//train//labels")
    val_labels_dir = Path("data//dataset_2_split//val//labels")
    test_labels_dir = Path("data//dataset_2_split//test//labels")
    
    for dir_path in [train_labels_dir, val_labels_dir, test_labels_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    all_images = []
    for crack_folder in all_crack_folders:
        crack_path = Path(crack_folder)
        if crack_path.exists():
            for ext in ['*.jpg', '*.jpeg', '*.png']:
                all_images.extend(crack_path.glob(ext))
    
    print(f"üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —Ç—Ä–µ—â–∏–Ω–∞–º–∏: {len(all_images)}")
    
    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º 70/15/15
    random.shuffle(all_images)
    train_split_idx = int(0.7 * len(all_images))
    val_split_idx = int(0.85 * len(all_images))
    
    train_images = all_images[:train_split_idx]
    val_images = all_images[train_split_idx:val_split_idx]
    test_images = all_images[val_split_idx:]
    
    print(f"üéØ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {len(train_images)} train, {len(val_images)} val, {len(test_images)} test")
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è train
    for image_path in train_images:
        annotation_content = create_full_image_annotation(image_path)
        annotation_filename = image_path.stem + '.txt'
        annotation_path = train_labels_dir / annotation_filename
        
        with open(annotation_path, 'w', encoding='utf-8') as f:
            f.write(annotation_content)
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è val
    for image_path in val_images:
        annotation_content = create_full_image_annotation(image_path)
        annotation_filename = image_path.stem + '.txt'
        annotation_path = val_labels_dir / annotation_filename
        
        with open(annotation_path, 'w', encoding='utf-8') as f:
            f.write(annotation_content)
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è test
    for image_path in test_images:
        annotation_content = create_full_image_annotation(image_path)
        annotation_filename = image_path.stem + '.txt'
        annotation_path = test_labels_dir / annotation_filename
        
        with open(annotation_path, 'w', encoding='utf-8') as f:
            f.write(annotation_content)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π:")
    print(f"   Train: {len(train_images)}")
    print(f"   Val: {len(val_images)}")
    print(f"   Test: {len(test_images)}")

def create_full_image_annotation(image_path):
    """–°–æ–∑–¥–∞–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –≥–¥–µ —Ç—Ä–µ—â–∏–Ω–∞ –∑–∞–Ω–∏–º–∞–µ—Ç –≤—Å—é —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é –æ–±–ª–∞—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    image = cv2.imread(str(image_path))
    if image is None:
        return "2 0.5 0.5 0.8 0.8"
    
    h, w = image.shape[:2]
    
    # –°–æ–∑–¥–∞–µ–º bounding box –≤ —Ü–µ–Ω—Ç—Ä–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    x_center = 0.5
    y_center = 0.5
    width = 0.8
    height = 0.8
    
    # –ö–ª–∞—Å—Å 2 = Crack
    return f"2 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}"

def create_smart_annotations_for_all():
    """–£–º–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –¥–ª—è train, val –∏ test"""
    
    crack_folders = {
        "train": ["data//training//–î–µ—Ñ–µ–∫—Ç 3"],
        "val": ["data//validation//–î–µ—Ñ–µ–∫—Ç 3"],
        "test": ["data//testing//–î–µ—Ñ–µ–∫—Ç 3"]
    }
    
    output_dirs = {
        "train": Path("data//dataset_2_split//train//labels"),
        "val": Path("data//dataset_2_split//val//labels"),
        "test": Path("data//dataset_2_split//test//labels")
    }
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    for dir_path in output_dirs.values():
        dir_path.mkdir(parents=True, exist_ok=True)
    
    detector = SmartCrackDetector()
    stats = {"train": 0, "val": 0, "test": 0}
    
    for split_type, folders in crack_folders.items():
        print(f"\nüéØ –£–ú–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê {split_type.upper()}:")
        
        for crack_folder in folders:
            crack_path = Path(crack_folder)
            if not crack_path.exists():
                print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {crack_path}")
                continue
                
            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png']:
                image_files.extend(crack_path.glob(ext))
            
            print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏: {crack_path}")
            print(f"   –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}")
            
            for image_path in image_files:
                # –î–µ—Ç–µ–∫—Ü–∏—è —Ç—Ä–µ—â–∏–Ω
                crack_bboxes = detector.detect_cracks(str(image_path))
                
                # –°–æ–∑–¥–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                annotation_content = detector.bboxes_to_yolo_format(crack_bboxes, str(image_path))
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                annotation_filename = image_path.stem + '.txt'
                annotation_path = output_dirs[split_type] / annotation_filename
                
                with open(annotation_path, 'w', encoding='utf-8') as f:
                    f.write(annotation_content)
                
                stats[split_type] += len(crack_bboxes) if crack_bboxes else 1
                print(f"   ‚úÖ {image_path.name} -> {len(crack_bboxes) if crack_bboxes else 1} —Ç—Ä–µ—â–∏–Ω -> {split_type}")

class SmartCrackDetector:
    """–£–º–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä —Ç—Ä–µ—â–∏–Ω –¥–ª—è —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–∏—Ö —Å–Ω–∏–º–∫–æ–≤"""
    
    def detect_cracks(self, image_path):
        """–î–µ—Ç–µ–∫—Ü–∏—è —Ç—Ä–µ—â–∏–Ω —Å –ø–æ–º–æ—â—å—é –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if image is None:
            return []
        
        h, w = image.shape
        
        # 1. –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(image)
        
        # 2. –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # 3. –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –ª–∏–Ω–µ–π–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
        kernel_line = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))
        morph = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_line)
        
        # 4. –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤
        contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        bboxes = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 100:  # –§–∏–ª—å—Ç—Ä –ø–æ –ø–ª–æ—â–∞–¥–∏
                x, y, w, h = cv2.boundingRect(contour)
                
                # –§–∏–ª—å—Ç—Ä –ø–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é —Å—Ç–æ—Ä–æ–Ω (—Ç—Ä–µ—â–∏–Ω—ã –≤—ã—Ç—è–Ω—É—Ç—ã–µ)
                aspect_ratio = w / h if h > 0 else 0
                if aspect_ratio > 2.0 or (aspect_ratio < 0.5 and h > 0):
                    bboxes.append([x, y, w, h])
        
        return bboxes
    
    def bboxes_to_yolo_format(self, bboxes, image_path):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è bbox –≤ YOLO —Ñ–æ—Ä–º–∞—Ç"""
        image = cv2.imread(image_path)
        if image is None:
            return "2 0.5 0.5 0.8 0.8"
        
        h, w = image.shape[:2]
        yolo_lines = []
        
        for bbox in bboxes:
            x, y, bbox_w, bbox_h = bbox
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            x_center = (x + bbox_w / 2) / w
            y_center = (y + bbox_h / 2) / h
            width = bbox_w / w
            height = bbox_h / h
            
            yolo_lines.append(f"2 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
        
        if not yolo_lines:
            return "2 0.5 0.5 0.8 0.8"
        
        return "\n".join(yolo_lines)

def check_all_annotations():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤–æ –≤—Å–µ—Ö –ø–∞–ø–∫–∞—Ö (train, val, test)"""
    train_dir = Path("data//dataset_2_split//train//labels")
    val_dir = Path("data//dataset_2_split//val//labels")
    test_dir = Path("data//dataset_2_split//test//labels")
    
    print("üîç –ü–†–û–í–ï–†–ö–ê –ê–ù–ù–û–¢–ê–¶–ò–ô:")
    
    for split_type, dir_path in [("TRAIN", train_dir), ("VAL", val_dir), ("TEST", test_dir)]:
        if dir_path.exists():
            txt_files = list(dir_path.glob("*.txt"))
            print(f"üìä {split_type}: {len(txt_files)} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤
            for txt_file in txt_files[:2]:
                with open(txt_file, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                lines = content.split('\n') if content else []
                print(f"   üìÑ {txt_file.name}: {len(lines)} —Ç—Ä–µ—â–∏–Ω")
        else:
            print(f"‚ùå {split_type}: –ø–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

# –ó–ê–ü–£–°–ö
if __name__ == "__main__":
    print("üöÄ –°–û–ó–î–ê–ù–ò–ï –ê–ù–ù–û–¢–ê–¶–ò–ô –î–õ–Ø TRAIN, VAL –ò TEST")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    check_all_annotations()
    
    print("\nüéØ –í–ê–†–ò–ê–ù–¢ 1: –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–∞–ø–∫–∞–º (training -> train, validation -> val, testing -> test)")
    create_crack_annotations_for_train_val_test()
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    check_all_annotations()