import os
import cv2
from pathlib import Path
import json
import random
import shutil

def create_crack_annotations_for_train_val_test():
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹ Ð´Ð»Ñ Ñ‚Ñ€ÐµÑ‰Ð¸Ð½ Ñ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸ÐµÐ¼ Ð¿Ð¾ train/val/test + ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹"""
    
    # ÐŸÑƒÑ‚Ð¸ Ðº Ð¿Ð°Ð¿ÐºÐ°Ð¼ Ñ Ñ‚Ñ€ÐµÑ‰Ð¸Ð½Ð°Ð¼Ð¸ (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ)
    crack_folders = {
        "train": ["data//data//training//Ð”ÐµÑ„ÐµÐºÑ‚ 3"],
        "test": ["data//data//testing//Ð”ÐµÑ„ÐµÐºÑ‚ 3"],
        "val": ["data//data//validation//Ð”ÐµÑ„ÐµÐºÑ‚ 3"]
    }
    
    # Ð’Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð¿Ð°Ð¿ÐºÐ¸ Ð´Ð»Ñ Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹ Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹
    output_dirs = {
        "train": {
            "labels": Path("data//dataset_2_split//train//labels"),
            "images": Path("data//dataset_2_split//train//images")
        },
        "test": {
            "labels": Path("data//dataset_2_split//test//labels"),
            "images": Path("data//dataset_2_split//test//images")
        },
        "val": {
            "labels": Path("data//dataset_2_split//val//labels"),
            "images": Path("data//dataset_2_split//val//images")
        }
    }
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸
    for split_type, dirs in output_dirs.items():
        dirs["labels"].mkdir(parents=True, exist_ok=True)
        dirs["images"].mkdir(parents=True, exist_ok=True)
    
    # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
    stats = {"train": 0, "val": 0, "test": 0}
    
    for split_type, folders in crack_folders.items():
        print(f"\nÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ {split_type.upper()} Ð”ÐÐÐÐ«Ð¥:")
        
        for crack_folder in folders:
            crack_path = Path(crack_folder)
            
            if not crack_path.exists():
                print(f"ÐŸÐ°Ð¿ÐºÐ° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°: {crack_path}")
                continue
                
            print(f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð°Ð¿ÐºÐ¸: {crack_path}")
            
            # Ð˜Ñ‰ÐµÐ¼ Ð²ÑÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð² Ð¿Ð°Ð¿ÐºÐµ
            image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
            image_files = []
            
            for ext in image_extensions:
                image_files.extend(crack_path.glob(ext))
                image_files.extend(crack_path.glob(ext.upper()))
            
            print(f" ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹: {len(image_files)}")
            
            for image_path in image_files:
                # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸ÑŽ
                annotation_content = create_full_image_annotation(image_path)
                
                # Ð˜Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¸
                annotation_filename = image_path.stem + '.txt'
                annotation_path = output_dirs[split_type]["labels"] / annotation_filename
                
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸ÑŽ
                with open(annotation_path, 'w', encoding='utf-8') as f:
                    f.write(annotation_content)
                
                dst_image_path = output_dirs[split_type]["images"] / image_path.name
                shutil.copy2(image_path, dst_image_path)
                
                stats[split_type] += 1
                print(f"Ð¡Ð¾Ð·Ð´Ð°Ð½Ð° Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ñ Ð¸ ÑÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ: {image_path.name} -> {split_type}")
    
    print(f"Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:")
    print(f"   Train: {stats['train']} Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹")
    print(f"   Val: {stats['val']} Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹")
    print(f"   Test: {stats['test']} Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹")
    
    print(f"Ð”Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²:")
    print(f"   Train: {output_dirs['train']['images']}")
    print(f"   Val: {output_dirs['val']['images']}")
    print(f"   Test: {output_dirs['test']['images']}")

def create_crack_annotations_with_split():
    """ÐÐ»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚: Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð½Ð° train/val/test + ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹"""
    
    # Ð’ÑÐµ Ð¿Ð°Ð¿ÐºÐ¸ Ñ Ñ‚Ñ€ÐµÑ‰Ð¸Ð½Ð°Ð¼Ð¸
    all_crack_folders = [
        "data//training//Ð”ÐµÑ„ÐµÐºÑ‚ 3",
        "data//testing//Ð”ÐµÑ„ÐµÐºÑ‚ 3", 
        "data//validation//Ð”ÐµÑ„ÐµÐºÑ‚ 3"
    ]
    
    # Ð’Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð¿Ð°Ð¿ÐºÐ¸
    train_labels_dir = Path("data//dataset_2_split//train//labels")
    val_labels_dir = Path("data//dataset_2_split//val//labels")
    test_labels_dir = Path("data//dataset_2_split//test//labels")
    
    train_images_dir = Path("data//dataset_2_split//train//images")
    val_images_dir = Path("data//dataset_2_split//val//images")
    test_images_dir = Path("data//dataset_2_split//test//images")
    
    for dir_path in [train_labels_dir, val_labels_dir, test_labels_dir,
                     train_images_dir, val_images_dir, test_images_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)
    
    # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    all_images = []
    for crack_folder in all_crack_folders:
        crack_path = Path(crack_folder)
        if crack_path.exists():
            for ext in ['*.jpg', '*.jpeg', '*.png']:
                all_images.extend(crack_path.glob(ext))
    
    print(f"Ð’ÑÐµÐ³Ð¾ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ñ Ñ‚Ñ€ÐµÑ‰Ð¸Ð½Ð°Ð¼Ð¸: {len(all_images)}")
    
    # ÐŸÐµÑ€ÐµÐ¼ÐµÑˆÐ¸Ð²Ð°ÐµÐ¼ Ð¸ Ñ€Ð°Ð·Ð´ÐµÐ»ÑÐµÐ¼ 70/15/15
    random.shuffle(all_images)
    train_split_idx = int(0.7 * len(all_images))
    val_split_idx = int(0.85 * len(all_images))
    
    train_images = all_images[:train_split_idx]
    val_images = all_images[train_split_idx:val_split_idx]
    test_images = all_images[val_split_idx:]
    
    print(f"Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ: {len(train_images)} train, {len(val_images)} val, {len(test_images)} test")
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¸ Ð¸ ÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    for image_path in train_images:
        annotation_content = create_full_image_annotation(image_path)
        annotation_filename = image_path.stem + '.txt'
        annotation_path = train_labels_dir / annotation_filename
        
        with open(annotation_path, 'w', encoding='utf-8') as f:
            f.write(annotation_content)
        
        shutil.copy2(image_path, train_images_dir / image_path.name)
    
    for image_path in val_images:
        annotation_content = create_full_image_annotation(image_path)
        annotation_filename = image_path.stem + '.txt'
        annotation_path = val_labels_dir / annotation_filename
        
        with open(annotation_path, 'w', encoding='utf-8') as f:
            f.write(annotation_content)
        
        shutil.copy2(image_path, val_images_dir / image_path.name)
    
    for image_path in test_images:
        annotation_content = create_full_image_annotation(image_path)
        annotation_filename = image_path.stem + '.txt'
        annotation_path = test_labels_dir / annotation_filename
        
        with open(annotation_path, 'w', encoding='utf-8') as f:
            f.write(annotation_content)
        
        shutil.copy2(image_path, test_images_dir / image_path.name)
    
    print(f"Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¾ Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹ Ð¸ ÑÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹:")
    print(f"   Train: {len(train_images)}")
    print(f"   Val: {len(val_images)}")
    print(f"   Test: {len(test_images)}")


def create_full_image_annotation(image_path):
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸ÑŽ Ð³Ð´Ðµ Ñ‚Ñ€ÐµÑ‰Ð¸Ð½Ð° Ð·Ð°Ð½Ð¸Ð¼Ð°ÐµÑ‚ Ð²ÑÑŽ Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ"""
    image = cv2.imread(str(image_path))
    if image is None:
        return "2 0.5 0.5 0.8 0.8"
    
    h, w = image.shape[:2]
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ bounding box Ð² Ñ†ÐµÐ½Ñ‚Ñ€Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    x_center = 0.5
    y_center = 0.5
    width = 0.8
    height = 0.8
    
    return f"2 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}"

class SmartCrackDetector:
    """Ð£Ð¼Ð½Ñ‹Ð¹ Ð´ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€ Ñ‚Ñ€ÐµÑ‰Ð¸Ð½ Ð´Ð»Ñ Ñ€ÐµÐ½Ñ‚Ð³ÐµÐ½Ð¾Ð²ÑÐºÐ¸Ñ… ÑÐ½Ð¸Ð¼ÐºÐ¾Ð²"""
    
    def detect_cracks(self, image_path):
        """Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ñ‚Ñ€ÐµÑ‰Ð¸Ð½ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð¼Ð¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if image is None:
            return []
        
        h, w = image.shape
        
        # Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚Ñ€Ð°ÑÑ‚Ð°
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(image)
        
        # Ð‘Ð¸Ð½Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # ÐœÐ¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ Ð²Ñ‹Ð´ÐµÐ»ÐµÐ½Ð¸Ñ Ð»Ð¸Ð½ÐµÐ¹Ð½Ñ‹Ñ… ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€
        kernel_line = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))
        morph = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_line)
        
        # ÐŸÐ¾Ð¸ÑÐº ÐºÐ¾Ð½Ñ‚ÑƒÑ€Ð¾Ð²
        contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        bboxes = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 100:  # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ Ð¿Ð¾ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / h if h > 0 else 0
                if aspect_ratio > 2.0 or (aspect_ratio < 0.5 and h > 0):
                    bboxes.append([x, y, w, h])
        
        return bboxes
    
    def bboxes_to_yolo_format(self, bboxes, image_path):
        """ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ bbox Ð² YOLO Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚"""
        image = cv2.imread(image_path)
        if image is None:
            return "2 0.5 0.5 0.8 0.8"
        
        h, w = image.shape[:2]
        yolo_lines = []
        
        for bbox in bboxes:
            x, y, bbox_w, bbox_h = bbox
            x_center = (x + bbox_w / 2) / w
            y_center = (y + bbox_h / 2) / h
            width = bbox_w / w
            height = bbox_h / h
            yolo_lines.append(f"2 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
        
        if not yolo_lines:
            return "2 0.5 0.5 0.8 0.8"
        
        return "\n".join(yolo_lines)

def create_smart_annotations_for_all():
    """Ð£Ð¼Ð½Ð¾Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹ Ñ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸ÐµÐ¹ Ð´Ð»Ñ train, val Ð¸ test + ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹"""
    
    crack_folders = {
        "train": ["data//training//Ð”ÐµÑ„ÐµÐºÑ‚ 3"],
        "val": ["data//validation//Ð”ÐµÑ„ÐµÐºÑ‚ 3"],
        "test": ["data//testing//Ð”ÐµÑ„ÐµÐºÑ‚ 3"]
    }
    
    output_dirs = {
        "train": {
            "labels": Path("data//dataset_2_split//train//labels"),
            "images": Path("data//dataset_2_split//train//images")
        },
        "val": {
            "labels": Path("data//dataset_2_split//val//labels"),
            "images": Path("data//dataset_2_split//val//images")
        },
        "test": {
            "labels": Path("data//dataset_2_split//test//labels"),
            "images": Path("data//dataset_2_split//test//images")
        }
    }
    
    for dirs in output_dirs.values():
        dirs["labels"].mkdir(parents=True, exist_ok=True)
        dirs["images"].mkdir(parents=True, exist_ok=True)
    
    detector = SmartCrackDetector()
    stats = {"train": 0, "val": 0, "test": 0}
    
    for split_type, folders in crack_folders.items():
        
        for crack_folder in folders:
            crack_path = Path(crack_folder)
            if not crack_path.exists():
                print(f"ÐŸÐ°Ð¿ÐºÐ° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°: {crack_path}")
                continue
                
            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png']:
                image_files.extend(crack_path.glob(ext))
            
            print(f"ðŸ” ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð°Ð¿ÐºÐ¸: {crack_path}")
            print(f"   ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹: {len(image_files)}")
            
            for image_path in image_files:
                crack_bboxes = detector.detect_cracks(str(image_path))
                annotation_content = detector.bboxes_to_yolo_format(crack_bboxes, str(image_path))
                annotation_filename = image_path.stem + '.txt'
                annotation_path = output_dirs[split_type]["labels"] / annotation_filename
                
                with open(annotation_path, 'w', encoding='utf-8') as f:
                    f.write(annotation_content)
                
                shutil.copy2(image_path, output_dirs[split_type]["images"] / image_path.name)
                
                stats[split_type] += len(crack_bboxes) if crack_bboxes else 1
                print(f" {image_path.name} -> {split_type} ({len(crack_bboxes)} Ñ‚Ñ€ÐµÑ‰Ð¸Ð½)")
    
    print("\nÐ˜Ñ‚Ð¾Ð³Ð¾Ð²Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:")
    for k, v in stats.items():
        print(f"   {k}: {v} Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹")


def check_all_annotations():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹ Ð²Ð¾ Ð²ÑÐµÑ… Ð¿Ð°Ð¿ÐºÐ°Ñ… (train, val, test)"""
    train_dir = Path("data//dataset_2_split//train//labels")
    val_dir = Path("data//dataset_2_split//val//labels")
    test_dir = Path("data//dataset_2_split//test//labels")
    
    print("ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ ÐÐÐÐžÐ¢ÐÐ¦Ð˜Ð™:")
    
    for split_type, dir_path in [("TRAIN", train_dir), ("VAL", val_dir), ("TEST", test_dir)]:
        if dir_path.exists():
            txt_files = list(dir_path.glob("*.txt"))
            print(f"ðŸ“Š {split_type}: {len(txt_files)} Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹")
            for txt_file in txt_files[:2]:
                with open(txt_file, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                lines = content.split('\n') if content else []
                print(f"   ðŸ“„ {txt_file.name}: {len(lines)} Ñ‚Ñ€ÐµÑ‰Ð¸Ð½")
        else:
            print(f"{split_type}: Ð¿Ð°Ð¿ÐºÐ° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")

if name == "main":
    check_all_annotations()
    print("\nÐ’ÐÐ Ð˜ÐÐÐ¢ 1: Ð¡Ð¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¿Ð°Ð¿ÐºÐ°Ð¼ (training -> train, validation -> val, testing -> test)")
    create_crack_annotations_for_train_val_test()
    check_all_annotations()